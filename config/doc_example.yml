name: doc_example
mode: docs
deploy_mode: cloud
start_loc: ./dataset
# Use existing Vespa app instead of generating new one
vespa_app_path: ./vespa_cloud
# Vespa Cloud configuration - set tenant at top level
cloud_tenant: your-tenant  # required for cloud mode (env/CLI still override)
vespa_cloud:
  # enpoint (TOKEN version not the MTLS)
  endpoint: https://your-vespa-cloud-endpoint-here.vespa-app.cloud
  # token: YOUR_TOKEN_HERE  # Or set VESPA_CLOUD_SECRET_TOKEN env var
  token: your-vespa-cloud-token-here

exclude:
  - "*.html"

# Optional: Web crawling specific parameters
doc_params:
  recursive: true               # Process subdirectories recursively (default: true)
  include_hidden: false         # Include hidden files (default: false)
  follow_symlinks: false        # Follow symbolic links (default: false)
  max_file_size_mb: 100         # Maximum file size in MB (optional)
  file_extensions:              # Only process these file types (optional)
    - .pdf
    - .docx
    - .txt
    - .md

# Optional: General parameters for downstream RAG processing
rag_params:
  embedding_model: sentence-transformers/all-mpnet-base-v2
  embedding_dim: 768              # Embedding dimension (default: 384)
  chunk_size: 512                 # Chunk size for text splitting (default: 1024)
  chunk_overlap: 50
  distance_metric: angular        # Distance metric: angular, euclidean, etc. (default: angular)
  device: cpu                     # Device for embeddings: 'cpu' or 'cuda' (default: cpu)
  max_tokens: 8192

llm_config:
  base_url: https://openrouter.ai/api/v1
  model: openai/gpt-4o-mini
  api_key: your-llm-api-key-here
